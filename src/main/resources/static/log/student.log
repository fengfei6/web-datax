
DataX (DATAX-OPENSOURCE-3.0), From Alibaba !
Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.


2020-04-02 11:56:50.437 [main] INFO  VMInfo - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2020-04-02 11:56:50.454 [main] INFO  Engine - the machine info  => 

	osInfo:	Oracle Corporation 1.8 25.60-b23
	jvmInfo:	Linux amd64 3.10.0-862.el7.x86_64
	cpu num:	1

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1

	GC Names	[Copy, MarkSweepCompact]

	MEMORY_NAME                    | allocation_size                | init_size                      
	Eden Space                     | 273.06MB                       | 273.06MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Survivor Space                 | 34.13MB                        | 34.13MB                        
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	Metaspace                      | -0.00MB                        | 0.00MB                         
	Tenured Gen                    | 682.69MB                       | 682.69MB                       


2020-04-02 11:56:50.479 [main] INFO  Engine - 
{
	"content":[
		{
			"reader":{
				"name":"mysqlreader",
				"parameter":{
					"column":[
						"*"
					],
					"connection":[
						{
							"jdbcUrl":[
								"jdbc:mysql://39.97.255.156:3307/lp_test"
							],
							"table":[
								"student"
							]
						}
					],
					"password":"**********",
					"username":"root"
				}
			},
			"writer":{
				"name":"mysqlwriter",
				"parameter":{
					"column":[
						"*"
					],
					"connection":[
						{
							"jdbcUrl":"jdbc:mysql://192.144.129.188:3306/test",
							"table":[
								"student"
							]
						}
					],
					"password":"******",
					"username":"root",
					"writeMode":"insert"
				}
			}
		}
	],
	"setting":{
		"errorLimit":{
			"percentage":0.02,
			"record":0
		},
		"speed":{
			"channel":3
		}
	}
}

2020-04-02 11:56:50.507 [main] WARN  Engine - prioriy set to 0, because NumberFormatException, the value is: null
2020-04-02 11:56:50.509 [main] INFO  PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=0
2020-04-02 11:56:50.509 [main] INFO  JobContainer - DataX jobContainer starts job.
2020-04-02 11:56:50.511 [main] INFO  JobContainer - Set jobId = 0
2020-04-02 11:56:51.589 [job-0] INFO  OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://39.97.255.156:3307/lp_test?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true.
2020-04-02 11:56:51.590 [job-0] WARN  OriginalConfPretreatmentUtil - 您的配置文件中的列配置存在一定的风险. 因为您未配置读取数据库表的列，当您的表字段个数、类型有变动时，可能影响任务正确性甚至会运行出错。请检查您的配置并作出修改.
2020-04-02 11:56:51.921 [job-0] INFO  OriginalConfPretreatmentUtil - table:[student] all columns:[
pass,name,id
].
2020-04-02 11:56:51.921 [job-0] WARN  OriginalConfPretreatmentUtil - 您的配置文件中的列配置信息存在风险. 因为您配置的写入数据库表的列为*，当您的表字段个数、类型有变动时，可能影响任务正确性甚至会运行出错。请检查您的配置并作出修改.
2020-04-02 11:56:51.923 [job-0] INFO  OriginalConfPretreatmentUtil - Write data [
insert INTO %s (pass,name,id) VALUES(?,?,?)
], which jdbcUrl like:[jdbc:mysql://192.144.129.188:3306/test?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true]
2020-04-02 11:56:51.923 [job-0] INFO  JobContainer - jobContainer starts to do prepare ...
2020-04-02 11:56:51.923 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] do prepare work .
2020-04-02 11:56:51.924 [job-0] INFO  JobContainer - DataX Writer.Job [mysqlwriter] do prepare work .
2020-04-02 11:56:51.924 [job-0] INFO  JobContainer - jobContainer starts to do split ...
2020-04-02 11:56:51.924 [job-0] INFO  JobContainer - Job set Channel-Number to 3 channels.
2020-04-02 11:56:51.927 [job-0] INFO  JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.
2020-04-02 11:56:51.927 [job-0] INFO  JobContainer - DataX Writer.Job [mysqlwriter] splits to [1] tasks.
2020-04-02 11:56:51.957 [job-0] INFO  JobContainer - jobContainer starts to do schedule ...
2020-04-02 11:56:51.961 [job-0] INFO  JobContainer - Scheduler starts [1] taskGroups.
2020-04-02 11:56:51.963 [job-0] INFO  JobContainer - Running by standalone Mode.
2020-04-02 11:56:51.996 [taskGroup-0] INFO  TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.
2020-04-02 11:56:52.000 [taskGroup-0] INFO  Channel - Channel set byte_speed_limit to -1, No bps activated.
2020-04-02 11:56:52.000 [taskGroup-0] INFO  Channel - Channel set record_speed_limit to -1, No tps activated.
2020-04-02 11:56:52.039 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started
2020-04-02 11:56:52.053 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Begin to read record by Sql: [select * from student 
] jdbcUrl:[jdbc:mysql://39.97.255.156:3307/lp_test?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2020-04-02 11:56:52.163 [0-0-0-reader] INFO  CommonRdbmsReader$Task - Finished read record by Sql: [select * from student 
] jdbcUrl:[jdbc:mysql://39.97.255.156:3307/lp_test?yearIsDateType=false&zeroDateTimeBehavior=convertToNull&tinyInt1isBit=false&rewriteBatchedStatements=true].
2020-04-02 11:56:52.201 [0-0-0-writer] WARN  CommonRdbmsWriter$Task - 回滚此次写入, 采用每次写入一行方式提交. 因为:Duplicate entry '123' for key 'PRIMARY'
2020-04-02 11:56:52.217 [0-0-0-writer] ERROR StdoutPluginCollector - 
com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry '123' for key 'PRIMARY'
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:1.8.0_60]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[na:1.8.0_60]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[na:1.8.0_60]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422) ~[na:1.8.0_60]
	at com.mysql.jdbc.Util.handleNewInstance(Util.java:404) ~[mysql-connector-java-5.1.38.jar:5.1.38]
	at com.mysql.jdbc.Util.getInstance(Util.java:387) ~[mysql-connector-java-5.1.38.jar:5.1.38]
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:932) ~[mysql-connector-java-5.1.38.jar:5.1.38]
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3878) ~[mysql-connector-java-5.1.38.jar:5.1.38]
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3814) ~[mysql-connector-java-5.1.38.jar:5.1.38]
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2478) ~[mysql-connector-java-5.1.38.jar:5.1.38]
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2625) ~[mysql-connector-java-5.1.38.jar:5.1.38]
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2551) ~[mysql-connector-java-5.1.38.jar:5.1.38]
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1861) ~[mysql-connector-java-5.1.38.jar:5.1.38]
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:1192) ~[mysql-connector-java-5.1.38.jar:5.1.38]
	at com.alibaba.datax.plugin.rdbms.writer.CommonRdbmsWriter$Task.doOneInsert(CommonRdbmsWriter.java:382) [plugin-rdbms-util-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.plugin.rdbms.writer.CommonRdbmsWriter$Task.doBatchInsert(CommonRdbmsWriter.java:362) [plugin-rdbms-util-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.plugin.rdbms.writer.CommonRdbmsWriter$Task.startWriteWithConnection(CommonRdbmsWriter.java:297) [plugin-rdbms-util-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.plugin.rdbms.writer.CommonRdbmsWriter$Task.startWrite(CommonRdbmsWriter.java:319) [plugin-rdbms-util-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.plugin.writer.mysqlwriter.MysqlWriter$Task.startWrite(MysqlWriter.java:78) [mysqlwriter-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.core.taskgroup.runner.WriterRunner.run(WriterRunner.java:56) [datax-core-0.0.1-SNAPSHOT.jar:na]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_60]
2020-04-02 11:56:52.220 [0-0-0-writer] ERROR StdoutPluginCollector - 脏数据: 
{"exception":"Duplicate entry '123' for key 'PRIMARY'","record":[{"byteSize":1,"index":0,"rawData":2,"type":"LONG"},{"byteSize":3,"index":1,"rawData":"qwe","type":"STRING"},{"byteSize":3,"index":2,"rawData":"123","type":"STRING"}],"type":"writer"}
2020-04-02 11:56:52.240 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[211]ms
2020-04-02 11:56:52.241 [taskGroup-0] INFO  TaskGroupContainer - taskGroup[0] completed it's tasks.
2020-04-02 11:57:01.998 [job-0] INFO  StandAloneJobContainerCommunicator - Total 3 records, 21 bytes | Speed 2B/s, 0 records/s | Error 1 records, 7 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2020-04-02 11:57:02.000 [job-0] ERROR JobContainer - 运行scheduler 模式[standalone]出错.
2020-04-02 11:57:02.001 [job-0] ERROR JobContainer - Exception when job run
com.alibaba.datax.common.exception.DataXException: Code:[Framework-14], Description:[DataX传输脏数据超过用户预期，该错误通常是由于源端数据存在较多业务脏数据导致，请仔细检查DataX汇报的脏数据日志信息, 或者您可以适当调大脏数据阈值 .].  - 脏数据条数检查不通过，限制是[0]条，但实际上捕获了[1]条.
	at com.alibaba.datax.common.exception.DataXException.asDataXException(DataXException.java:26) ~[datax-common-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.core.util.ErrorRecordChecker.checkRecordLimit(ErrorRecordChecker.java:58) ~[datax-core-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.core.job.scheduler.AbstractScheduler.schedule(AbstractScheduler.java:89) ~[datax-core-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.core.job.JobContainer.schedule(JobContainer.java:535) ~[datax-core-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.core.job.JobContainer.start(JobContainer.java:119) ~[datax-core-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.core.Engine.start(Engine.java:92) [datax-core-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.core.Engine.entry(Engine.java:171) [datax-core-0.0.1-SNAPSHOT.jar:na]
	at com.alibaba.datax.core.Engine.main(Engine.java:204) [datax-core-0.0.1-SNAPSHOT.jar:na]
2020-04-02 11:57:02.002 [job-0] INFO  StandAloneJobContainerCommunicator - Total 3 records, 21 bytes | Speed 21B/s, 3 records/s | Error 1 records, 7 bytes |  All Task WaitWriterTime 0.000s |  All Task WaitReaderTime 0.000s | Percentage 100.00%
2020-04-02 11:57:02.003 [job-0] ERROR Engine - 

经DataX智能分析,该任务最可能的错误原因是:
com.alibaba.datax.common.exception.DataXException: Code:[Framework-14], Description:[DataX传输脏数据超过用户预期，该错误通常是由于源端数据存在较多业务脏数据导致，请仔细检查DataX汇报的脏数据日志信息, 或者您可以适当调大脏数据阈值 .].  - 脏数据条数检查不通过，限制是[0]条，但实际上捕获了[1]条.
	at com.alibaba.datax.common.exception.DataXException.asDataXException(DataXException.java:26)
	at com.alibaba.datax.core.util.ErrorRecordChecker.checkRecordLimit(ErrorRecordChecker.java:58)
	at com.alibaba.datax.core.job.scheduler.AbstractScheduler.schedule(AbstractScheduler.java:89)
	at com.alibaba.datax.core.job.JobContainer.schedule(JobContainer.java:535)
	at com.alibaba.datax.core.job.JobContainer.start(JobContainer.java:119)
	at com.alibaba.datax.core.Engine.start(Engine.java:92)
	at com.alibaba.datax.core.Engine.entry(Engine.java:171)
	at com.alibaba.datax.core.Engine.main(Engine.java:204)

